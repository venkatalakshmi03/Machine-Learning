{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "HW 10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2vkAjHgS5sl"
      },
      "source": [
        "### 1) What are the main motivations for reducing a datasetâ€™s dimensionality? - 0.5 points\n",
        "### What are the main drawbacks? - 0.5 points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afXW_M6xJd-M"
      },
      "source": [
        "Advantages of reducing datasets dimensionality\n",
        "To speed up training algorithm (in some cases it can result in removing noise and redundant features, making the training algorithm perform better).\n",
        "For visualization i.e to visualize the data and gain insights on the most important features. Visualization becomes easy when data is reduced to very low dimensions such as 2D or 3D\n",
        "Reduce memory/disk needed to store data i.e compression\n",
        "Reduces overfitting.Overfitting mainly occurs when there are too many variables in the dataset. So, PCA helps in overcoming the overfitting issue by reducing the number of features."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0RL09wUKMzH"
      },
      "source": [
        "Drawbacks\n",
        "It may lead to some amount of data loss.\n",
        "After performing PCA, original features will turn into Principal Components and are the linear combination of original features. Principal Components are not as readable and interpretable as original features.\n",
        "PCA tends to find linear correlations between variables, which is sometimes undesirable.\n",
        "PCA fails in cases where mean and covariance are not enough to define datasets.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNC4pS-bmN66"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier  #Random Forest algorithm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV \n",
        "from sklearn.model_selection import cross_val_score\n",
        "import time\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcR9pgtNS5s3"
      },
      "source": [
        "### Load the MNIST dataset (given below) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9h5A43PS5s4",
        "outputId": "1f495882-ce13-49b8-a95c-e408fdcd8d87"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "mnist.keys()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'DESCR', 'details', 'categories', 'url'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk9EBZqalsm4"
      },
      "source": [
        "X = mnist.data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENUteQrgmaN5"
      },
      "source": [
        "y = mnist.target"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNp9IbOalswy"
      },
      "source": [
        "X_pd = pd.DataFrame(X)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGKPqXz1mdg7"
      },
      "source": [
        "y_pd = pd.DataFrame(y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "aYnpkO32mTd7",
        "outputId": "d1170cc6-442d-490d-e18e-59c96e6d7e33"
      },
      "source": [
        "X_pd.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>147.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5    6    ...  777  778  779  780  781  782  783\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6DVW45OamgtG",
        "outputId": "d095259a-34ce-4be2-8920-b831c42a3fd5"
      },
      "source": [
        "y_pd.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  5\n",
              "1  0\n",
              "2  4\n",
              "3  1\n",
              "4  9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtJb-WT-mIUV"
      },
      "source": [
        "X_scale = StandardScaler().fit_transform(X_pd) # PCA is not scale invariant hence scaling the data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCEo4-ztnkPQ"
      },
      "source": [
        "X_scale_pd = pd.DataFrame(X_scale)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "_BoFXDBUnozy",
        "outputId": "eb106c0f-3a9a-401e-cc9f-d9419db5a61d"
      },
      "source": [
        "X_scale_pd.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.00409</td>\n",
              "      <td>-0.005328</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>-0.005766</td>\n",
              "      <td>-0.008565</td>\n",
              "      <td>-0.011368</td>\n",
              "      <td>-0.014649</td>\n",
              "      <td>-0.019199</td>\n",
              "      <td>-0.024465</td>\n",
              "      <td>-0.030164</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.135972</td>\n",
              "      <td>-0.116821</td>\n",
              "      <td>-0.093024</td>\n",
              "      <td>-0.072208</td>\n",
              "      <td>-0.052605</td>\n",
              "      <td>-0.036664</td>\n",
              "      <td>-0.022296</td>\n",
              "      <td>-0.012815</td>\n",
              "      <td>-0.006075</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.005361</td>\n",
              "      <td>-0.008382</td>\n",
              "      <td>-0.014943</td>\n",
              "      <td>-0.021349</td>\n",
              "      <td>-0.026032</td>\n",
              "      <td>-0.03116</td>\n",
              "      <td>-0.041887</td>\n",
              "      <td>-0.045593</td>\n",
              "      <td>-0.051582</td>\n",
              "      <td>-0.055581</td>\n",
              "      <td>-0.059582</td>\n",
              "      <td>-0.056139</td>\n",
              "      <td>-0.050718</td>\n",
              "      <td>-0.042112</td>\n",
              "      <td>-0.032951</td>\n",
              "      <td>-0.023387</td>\n",
              "      <td>-0.01675</td>\n",
              "      <td>-0.010638</td>\n",
              "      <td>-0.008339</td>\n",
              "      <td>-0.005342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.00409</td>\n",
              "      <td>-0.005328</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>-0.005766</td>\n",
              "      <td>-0.008565</td>\n",
              "      <td>-0.011368</td>\n",
              "      <td>-0.014649</td>\n",
              "      <td>-0.019199</td>\n",
              "      <td>-0.024465</td>\n",
              "      <td>-0.030164</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.135972</td>\n",
              "      <td>-0.116821</td>\n",
              "      <td>-0.093024</td>\n",
              "      <td>-0.072208</td>\n",
              "      <td>-0.052605</td>\n",
              "      <td>-0.036664</td>\n",
              "      <td>-0.022296</td>\n",
              "      <td>-0.012815</td>\n",
              "      <td>-0.006075</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.005361</td>\n",
              "      <td>-0.008382</td>\n",
              "      <td>-0.014943</td>\n",
              "      <td>-0.021349</td>\n",
              "      <td>-0.026032</td>\n",
              "      <td>-0.03116</td>\n",
              "      <td>-0.041887</td>\n",
              "      <td>-0.045593</td>\n",
              "      <td>-0.051582</td>\n",
              "      <td>-0.055581</td>\n",
              "      <td>-0.059582</td>\n",
              "      <td>-0.056139</td>\n",
              "      <td>-0.050718</td>\n",
              "      <td>-0.042112</td>\n",
              "      <td>-0.032951</td>\n",
              "      <td>-0.023387</td>\n",
              "      <td>-0.01675</td>\n",
              "      <td>-0.010638</td>\n",
              "      <td>-0.008339</td>\n",
              "      <td>-0.005342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.00409</td>\n",
              "      <td>-0.005328</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>-0.005766</td>\n",
              "      <td>-0.008565</td>\n",
              "      <td>-0.011368</td>\n",
              "      <td>-0.014649</td>\n",
              "      <td>-0.019199</td>\n",
              "      <td>-0.024465</td>\n",
              "      <td>-0.030164</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.135972</td>\n",
              "      <td>-0.116821</td>\n",
              "      <td>-0.093024</td>\n",
              "      <td>-0.072208</td>\n",
              "      <td>-0.052605</td>\n",
              "      <td>-0.036664</td>\n",
              "      <td>-0.022296</td>\n",
              "      <td>-0.012815</td>\n",
              "      <td>-0.006075</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.005361</td>\n",
              "      <td>-0.008382</td>\n",
              "      <td>-0.014943</td>\n",
              "      <td>-0.021349</td>\n",
              "      <td>-0.026032</td>\n",
              "      <td>-0.03116</td>\n",
              "      <td>-0.041887</td>\n",
              "      <td>-0.045593</td>\n",
              "      <td>-0.051582</td>\n",
              "      <td>-0.055581</td>\n",
              "      <td>-0.059582</td>\n",
              "      <td>-0.056139</td>\n",
              "      <td>-0.050718</td>\n",
              "      <td>-0.042112</td>\n",
              "      <td>-0.032951</td>\n",
              "      <td>-0.023387</td>\n",
              "      <td>-0.01675</td>\n",
              "      <td>-0.010638</td>\n",
              "      <td>-0.008339</td>\n",
              "      <td>-0.005342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.00409</td>\n",
              "      <td>-0.005328</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>-0.005766</td>\n",
              "      <td>-0.008565</td>\n",
              "      <td>-0.011368</td>\n",
              "      <td>-0.014649</td>\n",
              "      <td>-0.019199</td>\n",
              "      <td>-0.024465</td>\n",
              "      <td>-0.030164</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.135972</td>\n",
              "      <td>-0.116821</td>\n",
              "      <td>-0.093024</td>\n",
              "      <td>-0.072208</td>\n",
              "      <td>-0.052605</td>\n",
              "      <td>-0.036664</td>\n",
              "      <td>-0.022296</td>\n",
              "      <td>-0.012815</td>\n",
              "      <td>-0.006075</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.005361</td>\n",
              "      <td>-0.008382</td>\n",
              "      <td>-0.014943</td>\n",
              "      <td>-0.021349</td>\n",
              "      <td>-0.026032</td>\n",
              "      <td>-0.03116</td>\n",
              "      <td>-0.041887</td>\n",
              "      <td>-0.045593</td>\n",
              "      <td>-0.051582</td>\n",
              "      <td>-0.055581</td>\n",
              "      <td>-0.059582</td>\n",
              "      <td>-0.056139</td>\n",
              "      <td>-0.050718</td>\n",
              "      <td>-0.042112</td>\n",
              "      <td>-0.032951</td>\n",
              "      <td>-0.023387</td>\n",
              "      <td>-0.01675</td>\n",
              "      <td>-0.010638</td>\n",
              "      <td>-0.008339</td>\n",
              "      <td>-0.005342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.00409</td>\n",
              "      <td>-0.005328</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>-0.005766</td>\n",
              "      <td>-0.008565</td>\n",
              "      <td>-0.011368</td>\n",
              "      <td>-0.014649</td>\n",
              "      <td>-0.019199</td>\n",
              "      <td>-0.024465</td>\n",
              "      <td>-0.030164</td>\n",
              "      <td>...</td>\n",
              "      <td>5.458896</td>\n",
              "      <td>11.214873</td>\n",
              "      <td>2.261153</td>\n",
              "      <td>-0.072208</td>\n",
              "      <td>-0.052605</td>\n",
              "      <td>-0.036664</td>\n",
              "      <td>-0.022296</td>\n",
              "      <td>-0.012815</td>\n",
              "      <td>-0.006075</td>\n",
              "      <td>-0.00378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.005361</td>\n",
              "      <td>-0.008382</td>\n",
              "      <td>-0.014943</td>\n",
              "      <td>-0.021349</td>\n",
              "      <td>-0.026032</td>\n",
              "      <td>-0.03116</td>\n",
              "      <td>-0.041887</td>\n",
              "      <td>-0.045593</td>\n",
              "      <td>-0.051582</td>\n",
              "      <td>-0.055581</td>\n",
              "      <td>-0.059582</td>\n",
              "      <td>-0.056139</td>\n",
              "      <td>-0.050718</td>\n",
              "      <td>-0.042112</td>\n",
              "      <td>-0.032951</td>\n",
              "      <td>-0.023387</td>\n",
              "      <td>-0.01675</td>\n",
              "      <td>-0.010638</td>\n",
              "      <td>-0.008339</td>\n",
              "      <td>-0.005342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5    ...       778       779  780  781  782  783\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.008339 -0.005342  0.0  0.0  0.0  0.0\n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.008339 -0.005342  0.0  0.0  0.0  0.0\n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.008339 -0.005342  0.0  0.0  0.0  0.0\n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.008339 -0.005342  0.0  0.0  0.0  0.0\n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.008339 -0.005342  0.0  0.0  0.0  0.0\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wplrC0cES5s6"
      },
      "source": [
        "### 2) Split it into a training set and a test set\n",
        "### Take the first 60,000 instances for training, and the remaining 10,000 for testing. - 1 point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZhSSI-GS5s7"
      },
      "source": [
        "X_train = X_scale_pd.iloc[0:60000,:]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgw5RYc9n6Yq",
        "outputId": "d4d3b8dd-0030-42ce-a2d3-a86928a4744d"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbMoFUoCn_HK"
      },
      "source": [
        "X_test = X_scale_pd.iloc[60000:70000,:]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3QaGnmQoFJl",
        "outputId": "832def6b-a958-49d3-bb14-38bf03455d2b"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foV6PcA5oLdC"
      },
      "source": [
        "y_train = y_pd.iloc[0:60000,:]\n",
        "y_test = y_pd.iloc[60000:70000, :]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P69qqYW0oWln",
        "outputId": "c7ff7a96-5107-4793-d250-f38cb59584aa"
      },
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 1)\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE43xCwpS5s8"
      },
      "source": [
        "### 3) Train a Random Forest classifier on the dataset and time how long it takes, - 1 point\n",
        "### then evaluate the resulting model on the test set. - 1 point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvEFq_PpS5s9",
        "outputId": "54eec976-4916-4ae9-ef43-bd9802988e35"
      },
      "source": [
        "rf=RandomForestClassifier(n_estimators=100)\n",
        "start = time.time()\n",
        "rf.fit(X_train,y_train.values.ravel())\n",
        "stop = time.time()\n",
        "print(f\"Training time in seconds: {stop - start}s\") "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time in seconds: 43.74654030799866s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0alpf7VsqtDG"
      },
      "source": [
        "pred=rf.predict(X_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_74B_Vwq3KM",
        "outputId": "7fcb8a72-47af-4d6d-e64f-456a1f8c2229"
      },
      "source": [
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.96      0.97      0.96      1032\n",
            "           3       0.96      0.96      0.96      1010\n",
            "           4       0.97      0.97      0.97       982\n",
            "           5       0.97      0.96      0.96       892\n",
            "           6       0.98      0.97      0.98       958\n",
            "           7       0.97      0.96      0.97      1028\n",
            "           8       0.96      0.95      0.96       974\n",
            "           9       0.96      0.95      0.96      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RW3nfAGP8lZ"
      },
      "source": [
        "# Accuracy of the model is 97%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDn7juG1S5s9"
      },
      "source": [
        "### 4) Next, use PCA to reduce the datasetâ€™s dimensionality, with an explained variance ratio of 95%. - 2 + 2 points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP3tVJ4JS5s-"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca=PCA(n_components=0.95) #if 0 < n_components < 1, select the number of components such that the amount of variance that needs to be explained is greater than the percentage specified by n_components \n",
        "data_1=pca.fit_transform(X_scale_pd)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gWdAyeoT9AI",
        "outputId": "2cc34e23-ccde-48be-86ae-d5c7b7e39c88"
      },
      "source": [
        "pca.n_components_ # It can be observed that by setting required varaince to 95% number of features are reduced to 332"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "332"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFKxgM6KUQEC",
        "outputId": "d3d62057-63fd-489d-817c-8e3511682307"
      },
      "source": [
        "sum(pca.explained_variance_ratio_)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9500311796713792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PsjJnkMQv-4"
      },
      "source": [
        "pca_1 = PCA(n_components= 334) # Checking variance by changing n_components it can be observed that for 334 features variance is 95.01%"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-To3I8WQ1Xf"
      },
      "source": [
        "data_2 = pca_1.fit_transform(X_scale_pd)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SryRuozQ_YT",
        "outputId": "53ec6f6b-89fa-4572-9bc2-900f20f0c67b"
      },
      "source": [
        "print(sum(pca_1.explained_variance_ratio_))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9501789743223269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smF2YTo0re1Z"
      },
      "source": [
        "df=pd.DataFrame(data_1)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "TJbtanmPre-p",
        "outputId": "dba2acab-c893-4b17-cba9-25269bb755a0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "      <th>300</th>\n",
              "      <th>301</th>\n",
              "      <th>302</th>\n",
              "      <th>303</th>\n",
              "      <th>304</th>\n",
              "      <th>305</th>\n",
              "      <th>306</th>\n",
              "      <th>307</th>\n",
              "      <th>308</th>\n",
              "      <th>309</th>\n",
              "      <th>310</th>\n",
              "      <th>311</th>\n",
              "      <th>312</th>\n",
              "      <th>313</th>\n",
              "      <th>314</th>\n",
              "      <th>315</th>\n",
              "      <th>316</th>\n",
              "      <th>317</th>\n",
              "      <th>318</th>\n",
              "      <th>319</th>\n",
              "      <th>320</th>\n",
              "      <th>321</th>\n",
              "      <th>322</th>\n",
              "      <th>323</th>\n",
              "      <th>324</th>\n",
              "      <th>325</th>\n",
              "      <th>326</th>\n",
              "      <th>327</th>\n",
              "      <th>328</th>\n",
              "      <th>329</th>\n",
              "      <th>330</th>\n",
              "      <th>331</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.891720</td>\n",
              "      <td>-4.929711</td>\n",
              "      <td>-0.093038</td>\n",
              "      <td>-8.064180</td>\n",
              "      <td>-0.751001</td>\n",
              "      <td>1.051980</td>\n",
              "      <td>0.283377</td>\n",
              "      <td>1.423696</td>\n",
              "      <td>-1.168523</td>\n",
              "      <td>2.406929</td>\n",
              "      <td>-1.330609</td>\n",
              "      <td>3.269546</td>\n",
              "      <td>3.022839</td>\n",
              "      <td>8.888603</td>\n",
              "      <td>-4.128878</td>\n",
              "      <td>2.254652</td>\n",
              "      <td>8.303377</td>\n",
              "      <td>-4.134214</td>\n",
              "      <td>4.402143</td>\n",
              "      <td>3.921384</td>\n",
              "      <td>-5.164933</td>\n",
              "      <td>0.260673</td>\n",
              "      <td>-2.431289</td>\n",
              "      <td>-2.781884</td>\n",
              "      <td>-2.212005</td>\n",
              "      <td>-2.672388</td>\n",
              "      <td>1.294495</td>\n",
              "      <td>5.017080</td>\n",
              "      <td>0.364979</td>\n",
              "      <td>-0.103957</td>\n",
              "      <td>-3.146816</td>\n",
              "      <td>1.711779</td>\n",
              "      <td>2.128689</td>\n",
              "      <td>2.107822</td>\n",
              "      <td>0.619344</td>\n",
              "      <td>-5.025392</td>\n",
              "      <td>0.864514</td>\n",
              "      <td>0.060800</td>\n",
              "      <td>0.883865</td>\n",
              "      <td>3.658248</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.651052</td>\n",
              "      <td>0.241625</td>\n",
              "      <td>1.707905</td>\n",
              "      <td>1.249879</td>\n",
              "      <td>-0.928440</td>\n",
              "      <td>-0.077113</td>\n",
              "      <td>1.653487</td>\n",
              "      <td>-0.335433</td>\n",
              "      <td>0.497120</td>\n",
              "      <td>0.267314</td>\n",
              "      <td>-0.105362</td>\n",
              "      <td>0.297722</td>\n",
              "      <td>0.873547</td>\n",
              "      <td>-1.760335</td>\n",
              "      <td>1.187746</td>\n",
              "      <td>-1.474289</td>\n",
              "      <td>-0.726226</td>\n",
              "      <td>0.465618</td>\n",
              "      <td>0.429916</td>\n",
              "      <td>-0.656616</td>\n",
              "      <td>-0.102483</td>\n",
              "      <td>0.569796</td>\n",
              "      <td>-0.781345</td>\n",
              "      <td>0.328257</td>\n",
              "      <td>-0.163896</td>\n",
              "      <td>-0.648395</td>\n",
              "      <td>0.128975</td>\n",
              "      <td>-0.635219</td>\n",
              "      <td>-0.102080</td>\n",
              "      <td>0.249711</td>\n",
              "      <td>0.155843</td>\n",
              "      <td>-0.130359</td>\n",
              "      <td>0.791173</td>\n",
              "      <td>0.168495</td>\n",
              "      <td>0.157279</td>\n",
              "      <td>-0.442585</td>\n",
              "      <td>-1.471752</td>\n",
              "      <td>0.301955</td>\n",
              "      <td>0.349144</td>\n",
              "      <td>-0.752368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.813530</td>\n",
              "      <td>-7.517560</td>\n",
              "      <td>-3.714185</td>\n",
              "      <td>-1.766171</td>\n",
              "      <td>0.891472</td>\n",
              "      <td>-5.107950</td>\n",
              "      <td>-0.134795</td>\n",
              "      <td>3.197223</td>\n",
              "      <td>-0.238224</td>\n",
              "      <td>-1.003382</td>\n",
              "      <td>-3.349344</td>\n",
              "      <td>-1.254795</td>\n",
              "      <td>-2.411946</td>\n",
              "      <td>-3.919341</td>\n",
              "      <td>-3.027826</td>\n",
              "      <td>-1.176719</td>\n",
              "      <td>-0.037599</td>\n",
              "      <td>1.468827</td>\n",
              "      <td>3.165507</td>\n",
              "      <td>0.936482</td>\n",
              "      <td>-3.624515</td>\n",
              "      <td>-1.837798</td>\n",
              "      <td>2.539826</td>\n",
              "      <td>0.077271</td>\n",
              "      <td>-1.914550</td>\n",
              "      <td>-0.119093</td>\n",
              "      <td>-1.706681</td>\n",
              "      <td>0.075744</td>\n",
              "      <td>-0.342225</td>\n",
              "      <td>0.260514</td>\n",
              "      <td>1.022326</td>\n",
              "      <td>1.606968</td>\n",
              "      <td>1.567860</td>\n",
              "      <td>-3.660889</td>\n",
              "      <td>-0.894668</td>\n",
              "      <td>-0.008198</td>\n",
              "      <td>-0.948927</td>\n",
              "      <td>-1.184021</td>\n",
              "      <td>0.882179</td>\n",
              "      <td>-1.000315</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.103752</td>\n",
              "      <td>0.392486</td>\n",
              "      <td>-0.285307</td>\n",
              "      <td>0.618808</td>\n",
              "      <td>-0.131727</td>\n",
              "      <td>-0.619418</td>\n",
              "      <td>-0.028074</td>\n",
              "      <td>0.099182</td>\n",
              "      <td>-0.020850</td>\n",
              "      <td>-0.414833</td>\n",
              "      <td>0.543655</td>\n",
              "      <td>0.200647</td>\n",
              "      <td>0.219050</td>\n",
              "      <td>-0.062917</td>\n",
              "      <td>-0.574691</td>\n",
              "      <td>-0.185562</td>\n",
              "      <td>-0.053774</td>\n",
              "      <td>-0.118423</td>\n",
              "      <td>0.022394</td>\n",
              "      <td>-0.231781</td>\n",
              "      <td>0.159026</td>\n",
              "      <td>0.069043</td>\n",
              "      <td>0.056652</td>\n",
              "      <td>0.283836</td>\n",
              "      <td>0.184992</td>\n",
              "      <td>-0.081271</td>\n",
              "      <td>0.250979</td>\n",
              "      <td>0.286398</td>\n",
              "      <td>-0.215919</td>\n",
              "      <td>0.142108</td>\n",
              "      <td>-0.080121</td>\n",
              "      <td>0.143971</td>\n",
              "      <td>-0.075292</td>\n",
              "      <td>-0.054148</td>\n",
              "      <td>-0.328657</td>\n",
              "      <td>-0.097342</td>\n",
              "      <td>-0.277915</td>\n",
              "      <td>-0.066247</td>\n",
              "      <td>-0.316840</td>\n",
              "      <td>-0.180312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.204835</td>\n",
              "      <td>9.824461</td>\n",
              "      <td>-5.752488</td>\n",
              "      <td>1.479673</td>\n",
              "      <td>4.397900</td>\n",
              "      <td>2.507393</td>\n",
              "      <td>18.927843</td>\n",
              "      <td>3.888938</td>\n",
              "      <td>2.443365</td>\n",
              "      <td>-0.145296</td>\n",
              "      <td>-7.377445</td>\n",
              "      <td>2.023420</td>\n",
              "      <td>0.683597</td>\n",
              "      <td>-0.330238</td>\n",
              "      <td>12.261370</td>\n",
              "      <td>9.560811</td>\n",
              "      <td>-4.691458</td>\n",
              "      <td>4.208711</td>\n",
              "      <td>4.465518</td>\n",
              "      <td>4.835956</td>\n",
              "      <td>9.232379</td>\n",
              "      <td>1.210316</td>\n",
              "      <td>-0.253012</td>\n",
              "      <td>-7.499449</td>\n",
              "      <td>-0.765113</td>\n",
              "      <td>-0.255858</td>\n",
              "      <td>3.207874</td>\n",
              "      <td>9.844513</td>\n",
              "      <td>2.167533</td>\n",
              "      <td>2.955643</td>\n",
              "      <td>-3.492020</td>\n",
              "      <td>3.398431</td>\n",
              "      <td>0.952555</td>\n",
              "      <td>-5.161981</td>\n",
              "      <td>0.233282</td>\n",
              "      <td>0.227608</td>\n",
              "      <td>-0.509848</td>\n",
              "      <td>-0.943464</td>\n",
              "      <td>-0.325656</td>\n",
              "      <td>6.115074</td>\n",
              "      <td>...</td>\n",
              "      <td>1.510956</td>\n",
              "      <td>0.019325</td>\n",
              "      <td>0.797093</td>\n",
              "      <td>-1.012156</td>\n",
              "      <td>-0.039252</td>\n",
              "      <td>-0.499276</td>\n",
              "      <td>-0.496772</td>\n",
              "      <td>-0.660710</td>\n",
              "      <td>-0.057071</td>\n",
              "      <td>-0.739862</td>\n",
              "      <td>0.797361</td>\n",
              "      <td>-1.361248</td>\n",
              "      <td>-0.006010</td>\n",
              "      <td>-0.704339</td>\n",
              "      <td>0.952413</td>\n",
              "      <td>0.223143</td>\n",
              "      <td>-0.923926</td>\n",
              "      <td>-0.215935</td>\n",
              "      <td>0.515815</td>\n",
              "      <td>-0.229273</td>\n",
              "      <td>-0.328838</td>\n",
              "      <td>-0.140172</td>\n",
              "      <td>0.275122</td>\n",
              "      <td>0.092775</td>\n",
              "      <td>-0.150415</td>\n",
              "      <td>2.089663</td>\n",
              "      <td>0.416112</td>\n",
              "      <td>0.840605</td>\n",
              "      <td>0.304753</td>\n",
              "      <td>-0.416915</td>\n",
              "      <td>0.333313</td>\n",
              "      <td>0.668359</td>\n",
              "      <td>-1.050376</td>\n",
              "      <td>-0.452535</td>\n",
              "      <td>0.122534</td>\n",
              "      <td>0.702811</td>\n",
              "      <td>1.210336</td>\n",
              "      <td>-1.227017</td>\n",
              "      <td>-0.579337</td>\n",
              "      <td>-0.585607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-6.534627</td>\n",
              "      <td>-4.029669</td>\n",
              "      <td>3.524017</td>\n",
              "      <td>-0.218098</td>\n",
              "      <td>5.606259</td>\n",
              "      <td>3.493731</td>\n",
              "      <td>1.445046</td>\n",
              "      <td>-4.683887</td>\n",
              "      <td>-0.613930</td>\n",
              "      <td>-2.533648</td>\n",
              "      <td>-2.276405</td>\n",
              "      <td>3.849409</td>\n",
              "      <td>-0.036696</td>\n",
              "      <td>-3.844612</td>\n",
              "      <td>-0.951812</td>\n",
              "      <td>2.209973</td>\n",
              "      <td>-0.917823</td>\n",
              "      <td>1.564761</td>\n",
              "      <td>-0.131848</td>\n",
              "      <td>-0.155584</td>\n",
              "      <td>-1.819958</td>\n",
              "      <td>-0.547340</td>\n",
              "      <td>-1.036494</td>\n",
              "      <td>-1.961018</td>\n",
              "      <td>1.536018</td>\n",
              "      <td>0.917744</td>\n",
              "      <td>-1.367578</td>\n",
              "      <td>-0.639071</td>\n",
              "      <td>0.991479</td>\n",
              "      <td>-1.049006</td>\n",
              "      <td>-0.348834</td>\n",
              "      <td>-1.436073</td>\n",
              "      <td>-0.542291</td>\n",
              "      <td>-1.614674</td>\n",
              "      <td>1.271152</td>\n",
              "      <td>-0.859385</td>\n",
              "      <td>-0.063320</td>\n",
              "      <td>0.016637</td>\n",
              "      <td>0.580517</td>\n",
              "      <td>-1.146231</td>\n",
              "      <td>...</td>\n",
              "      <td>0.147042</td>\n",
              "      <td>0.081828</td>\n",
              "      <td>-0.458821</td>\n",
              "      <td>-0.253698</td>\n",
              "      <td>-0.221445</td>\n",
              "      <td>0.070159</td>\n",
              "      <td>0.139245</td>\n",
              "      <td>0.297227</td>\n",
              "      <td>0.035695</td>\n",
              "      <td>-0.198597</td>\n",
              "      <td>-0.402531</td>\n",
              "      <td>-0.222471</td>\n",
              "      <td>-0.102962</td>\n",
              "      <td>0.497349</td>\n",
              "      <td>-0.317365</td>\n",
              "      <td>-0.083348</td>\n",
              "      <td>0.339681</td>\n",
              "      <td>-0.003559</td>\n",
              "      <td>0.554188</td>\n",
              "      <td>0.124095</td>\n",
              "      <td>0.129885</td>\n",
              "      <td>-0.148278</td>\n",
              "      <td>0.267446</td>\n",
              "      <td>0.032364</td>\n",
              "      <td>0.097750</td>\n",
              "      <td>-0.023052</td>\n",
              "      <td>-0.001496</td>\n",
              "      <td>-0.086800</td>\n",
              "      <td>-0.142715</td>\n",
              "      <td>0.135044</td>\n",
              "      <td>-0.314217</td>\n",
              "      <td>-0.124090</td>\n",
              "      <td>-0.325576</td>\n",
              "      <td>-0.443792</td>\n",
              "      <td>0.208390</td>\n",
              "      <td>0.067788</td>\n",
              "      <td>-0.004242</td>\n",
              "      <td>0.064486</td>\n",
              "      <td>-0.141908</td>\n",
              "      <td>-0.005184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-5.251618</td>\n",
              "      <td>3.278848</td>\n",
              "      <td>-6.182219</td>\n",
              "      <td>1.462658</td>\n",
              "      <td>-1.667989</td>\n",
              "      <td>-0.580801</td>\n",
              "      <td>-0.565828</td>\n",
              "      <td>-3.129538</td>\n",
              "      <td>0.005915</td>\n",
              "      <td>-0.972611</td>\n",
              "      <td>4.690669</td>\n",
              "      <td>0.145346</td>\n",
              "      <td>0.236667</td>\n",
              "      <td>-1.990848</td>\n",
              "      <td>-1.743585</td>\n",
              "      <td>-0.877407</td>\n",
              "      <td>-1.752464</td>\n",
              "      <td>5.607420</td>\n",
              "      <td>0.249852</td>\n",
              "      <td>1.955801</td>\n",
              "      <td>-0.892523</td>\n",
              "      <td>-0.189549</td>\n",
              "      <td>-0.780645</td>\n",
              "      <td>1.477916</td>\n",
              "      <td>-4.034878</td>\n",
              "      <td>-1.375146</td>\n",
              "      <td>-0.483954</td>\n",
              "      <td>-1.224623</td>\n",
              "      <td>-0.765716</td>\n",
              "      <td>-0.119686</td>\n",
              "      <td>0.582360</td>\n",
              "      <td>1.932977</td>\n",
              "      <td>2.551989</td>\n",
              "      <td>-0.907934</td>\n",
              "      <td>-3.326028</td>\n",
              "      <td>3.304077</td>\n",
              "      <td>0.221052</td>\n",
              "      <td>-1.603824</td>\n",
              "      <td>-0.236674</td>\n",
              "      <td>0.920848</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213628</td>\n",
              "      <td>0.607253</td>\n",
              "      <td>0.113240</td>\n",
              "      <td>0.317144</td>\n",
              "      <td>0.306239</td>\n",
              "      <td>-1.265515</td>\n",
              "      <td>-0.180701</td>\n",
              "      <td>-0.055486</td>\n",
              "      <td>0.154955</td>\n",
              "      <td>0.495032</td>\n",
              "      <td>-0.800311</td>\n",
              "      <td>-0.234991</td>\n",
              "      <td>-0.582099</td>\n",
              "      <td>-0.616740</td>\n",
              "      <td>0.644765</td>\n",
              "      <td>0.582902</td>\n",
              "      <td>-0.226976</td>\n",
              "      <td>0.512365</td>\n",
              "      <td>-0.058022</td>\n",
              "      <td>0.390948</td>\n",
              "      <td>0.520445</td>\n",
              "      <td>0.021403</td>\n",
              "      <td>-0.756604</td>\n",
              "      <td>-0.193905</td>\n",
              "      <td>-0.389989</td>\n",
              "      <td>0.370849</td>\n",
              "      <td>0.402171</td>\n",
              "      <td>-1.054009</td>\n",
              "      <td>-0.209151</td>\n",
              "      <td>0.333395</td>\n",
              "      <td>0.145473</td>\n",
              "      <td>-0.138217</td>\n",
              "      <td>0.372599</td>\n",
              "      <td>0.129113</td>\n",
              "      <td>-0.887090</td>\n",
              "      <td>0.386616</td>\n",
              "      <td>1.051650</td>\n",
              "      <td>-0.171021</td>\n",
              "      <td>-0.359139</td>\n",
              "      <td>-0.719385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 332 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       329       330       331\n",
              "0 -0.891720 -4.929711 -0.093038  ...  0.301955  0.349144 -0.752368\n",
              "1  8.813530 -7.517560 -3.714185  ... -0.066247 -0.316840 -0.180312\n",
              "2  2.204835  9.824461 -5.752488  ... -1.227017 -0.579337 -0.585607\n",
              "3 -6.534627 -4.029669  3.524017  ...  0.064486 -0.141908 -0.005184\n",
              "4 -5.251618  3.278848 -6.182219  ... -0.171021 -0.359139 -0.719385\n",
              "\n",
              "[5 rows x 332 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjQOqmHqUgzt",
        "outputId": "341064f4-b90d-47c9-dd5e-0acabacc5ec1"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmCsLcQurksJ"
      },
      "source": [
        "X_train_1 = df.iloc[0:60000,:]\n",
        "X_test_1 = df.iloc[60000:70000,:]"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rblgadEJrqG2",
        "outputId": "492e8d79-6293-419a-bc45-964467a52c64"
      },
      "source": [
        "print(X_train_1.shape)\n",
        "print(X_test_1.shape)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 332)\n",
            "(10000, 332)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEIEGaWbS5s_"
      },
      "source": [
        "### 5)  Train a new Random Forest classifier on the reduced dataset and see how long it takes. - 1 point\n",
        "### Was training much faster? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDawen98S5tA"
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators=100)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwWkLradUtE7",
        "outputId": "b6595786-b126-4372-a401-93e11f039a22"
      },
      "source": [
        "start = time.time()\n",
        "rf.fit(X_train_1,y_train.values.ravel())\n",
        "stop = time.time()\n",
        "print(f\"Training time in seconds: {stop - start}s\") "
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time in seconds: 154.9591429233551s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ8GJzvHS5tA"
      },
      "source": [
        "### 6) Next evaluate the classifier on the test set: how does it compare to the previous classifier? - 1 point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVtveMoTS5tB"
      },
      "source": [
        "pred_1 =rf.predict(X_test_1)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMPJEynW6F2f",
        "outputId": "cec806f9-33b3-43bf-a9f5-81742060faaf"
      },
      "source": [
        "print(confusion_matrix(y_test, pred_1))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 960    0    1    1    1    5    9    2    1    0]\n",
            " [   0 1115    6    1    2    1    6    0    4    0]\n",
            " [  10    0  962   16    2    0    7   11   22    2]\n",
            " [   1    0   13  949    0    8    2   16   15    6]\n",
            " [   2    1    9    1  934    0    6    4    3   22]\n",
            " [   6    0    3   41    4  798   10    7   17    6]\n",
            " [  10    2    5    1    7   12  918    0    3    0]\n",
            " [   1    6   25    7    7    2    0  948    3   29]\n",
            " [   7    0   10   24    9   24    5    8  883    4]\n",
            " [   7    4    4   20   32    3    0   31    4  904]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH64k3gk6Vsh",
        "outputId": "0bcce041-e652-46fa-8559-ef51ebd4a1aa"
      },
      "source": [
        "print(\"Accuracy score of model\")\n",
        "print(accuracy_score(y_test, pred_1))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score of model\n",
            "0.9371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CWzxzvttI8t",
        "outputId": "aa5246ef-1559-4389-d270-05aea0a8e407"
      },
      "source": [
        "print(classification_report(y_test, pred_1))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       980\n",
            "           1       0.99      0.98      0.98      1135\n",
            "           2       0.92      0.93      0.93      1032\n",
            "           3       0.89      0.94      0.91      1010\n",
            "           4       0.94      0.94      0.94       982\n",
            "           5       0.94      0.91      0.92       892\n",
            "           6       0.95      0.96      0.95       958\n",
            "           7       0.93      0.93      0.93      1028\n",
            "           8       0.94      0.91      0.92       974\n",
            "           9       0.93      0.90      0.91      1009\n",
            "\n",
            "    accuracy                           0.94     10000\n",
            "   macro avg       0.94      0.94      0.94     10000\n",
            "weighted avg       0.94      0.94      0.94     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgGVGrgJV2PJ"
      },
      "source": [
        "# It can be observed that accuracy for model using reduced number of dimensions is 93.7% which is lesser than accuracy of model using all input features 97%\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "w-YFjw7jXKwR",
        "outputId": "785a8ea4-a7eb-4188-b9d7-86ea985cb946"
      },
      "source": [
        "#elbow plot to check the optimal number of features that can explain 95% of the variance in data\n",
        "\n",
        "var=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
        "plt.ylabel('% Variance Explained')\n",
        "plt.xlabel('Number of Features')\n",
        "plt.title('PCA Analysis')\n",
        "plt.ylim(30,100.5)\n",
        "plt.style.context('seaborn-whitegrid')\n",
        "plt.plot(var)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f344bacae10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgu4EEQtXThd",
        "outputId": "2afc6d1c-5926-4acb-e792-ee92bce10967"
      },
      "source": [
        "# Checking accuracy of model with various number of PCA components\n",
        "from sklearn.metrics import accuracy_score\n",
        "for i in range(40,332,30):\n",
        "  pca=PCA(n_components=i) \n",
        "  data_new = pca.fit_transform(X_scale_pd)\n",
        "  vr = sum(pca.explained_variance_ratio_)\n",
        "  df=pd.DataFrame(data_new)\n",
        "  X_train_1 = df.iloc[0:60000,:]\n",
        "  X_test_1 = df.iloc[60000:70000,:]\n",
        "  start = time.time()\n",
        "  rf.fit(X_train_1,y_train.values.ravel())\n",
        "  stop = time.time()\n",
        "  #print(f\"Training time in seconds: {stop - start}s\")\n",
        "  pred_1 =rf.predict(X_test_1)\n",
        "  accuracy = accuracy_score(y_test, pred_1)\n",
        "  print(\"Number of components :%d, percentage of explained variance : %f, accuracy percentage of model : %f, training time in seconds : %f\" % (i, (vr*100.0), (accuracy*100.0),(stop-start)))\t"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of components :40, percentage of explained variance : 50.496279, accuracy percentage of model : 94.370000, training time in seconds : 50.514341\n",
            "Number of components :70, percentage of explained variance : 62.001397, accuracy percentage of model : 94.540000, training time in seconds : 66.878171\n",
            "Number of components :100, percentage of explained variance : 70.065963, accuracy percentage of model : 94.350000, training time in seconds : 83.633716\n",
            "Number of components :130, percentage of explained variance : 76.465736, accuracy percentage of model : 94.260000, training time in seconds : 91.746289\n",
            "Number of components :160, percentage of explained variance : 81.349467, accuracy percentage of model : 94.420000, training time in seconds : 99.963011\n",
            "Number of components :190, percentage of explained variance : 85.328414, accuracy percentage of model : 94.270000, training time in seconds : 107.874175\n",
            "Number of components :220, percentage of explained variance : 88.430799, accuracy percentage of model : 94.020000, training time in seconds : 117.033894\n",
            "Number of components :250, percentage of explained variance : 90.822122, accuracy percentage of model : 93.930000, training time in seconds : 126.661687\n",
            "Number of components :280, percentage of explained variance : 92.651541, accuracy percentage of model : 93.960000, training time in seconds : 135.599907\n",
            "Number of components :310, percentage of explained variance : 94.082770, accuracy percentage of model : 93.720000, training time in seconds : 143.416521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlPk8kz_5Nv_"
      },
      "source": [
        "# Observations :\n",
        "It can be observed that with number of components = 70 , model gives highest accuracy with 94.5% than with model with 332 components\n",
        "As number of components increases, explained variance increases but training time increases and accuracy of model decreases\n",
        "Increasing the number of features willnot always improve classification accuracy and might lead to drop in performance\n",
        "Optimum set of features of lowerdimensionality to improve classification accuracy is n = 70 for this dataset \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}