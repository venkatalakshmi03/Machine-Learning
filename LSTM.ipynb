{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V6kEfCi93mJ"
      },
      "source": [
        " **Train a 2-layer bidirectional LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52EhDXPc-Dh9"
      },
      "source": [
        "Use the IMDB movie review sentiment data using keras.datasets.imdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXuZIyHP_YMX"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KyFwngY94jV"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Input, Dense, Dropout, Embedding, Flatten, LSTM, Bidirectional\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb42e3P9APfh"
      },
      "source": [
        "Load the IMDB movie review sentiment data using keras.datasets.imdb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PtD2o4a3rsC"
      },
      "source": [
        "#limit the total number of words that we are interested in modeling to the 20000 most frequent words, and zero out the rest\n",
        "max_features = 20000  # Considering top 20000 features\n",
        "#constrain each review to be 200 words, truncating long reviews and pad the shorter reviews with zero values\n",
        "maxlen = 200"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZsx7zu15AKI",
        "outputId": "0c5a48fb-1653-4482-f88e-27be88ebf46b"
      },
      "source": [
        "(X_train, y_train), (X_val, y_val) = keras.datasets.imdb.load_data(num_words=max_features)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU-yCNjE5AXY",
        "outputId": "05bff8d9-e941-490d-f3ba-270be5b77d0d"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "#  dataset split into (50%) train and (50%) test sets"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cohq4wXPyNK",
        "outputId": "ed4209d1-6634-49a6-ad94-10dab17228e7"
      },
      "source": [
        "#The words have been replaced by integers that indicate the ordered frequency of each word in the dataset. \n",
        "#The sentences in each review are therefore comprised of a sequence of integers\n",
        "X_train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "       ...,\n",
              "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 2]),\n",
              "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWqttYdM5byB",
        "outputId": "31ed4e1d-43ee-492a-82d1-7179ff0f9f6e"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ4UVrZNAcB-"
      },
      "source": [
        "Training and Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNe-GOveAlHH"
      },
      "source": [
        "#Truncate and pad the input sequences so that they are all the same length for modeling. \n",
        "#The model will learn the zero values carry no information so indeed the sequences are not the same length in terms of content, but same length vectors is required to perform the computation in Keras\n",
        "X_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_val = keras.preprocessing.sequence.pad_sequences(X_val, maxlen=maxlen)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqLF5r4ftPyS",
        "outputId": "03c1179e-b703-48be-aee1-b19a06b92241"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhH71PXdtU-7",
        "outputId": "962eab7e-00cd-4f78-dec0-7eb2448dd7b5"
      },
      "source": [
        "X_val.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1Ociphi-P6M"
      },
      "source": [
        "Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYxuua2cAmVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea39c90f-0732-403f-ca31-8ad4275ad5e1"
      },
      "source": [
        "# Building model using functional API\n",
        "\n",
        "# Input for variable-length sequences of integers\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "# Embed each word integer in a 128-dimensional vector\n",
        "# Word embedding technique words are encoded as real-valued vectors in a high dimensional space, where the similarity between words in terms of meaning translates to closeness in the vector space\n",
        "x = layers.Embedding(max_features, 128)(inputs)\n",
        "# Add 2 bidirectional LSTMs\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "# Add a classifier\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Sigmoid activation as it is binary classification\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, None, 128)         98816     \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,757,761\n",
            "Trainable params: 2,757,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y6ZJZDBXVZS"
      },
      "source": [
        "#Building model without using Functional API\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Bidirectional(LSTM(64, return_sequences=True))) # Bidirectional LSTM layer with 64 memory units (smart neurons)\n",
        "model2.add(Bidirectional(LSTM(64)))\n",
        "model2.add(Dropout(0.5)) # Dropout layer is added to remove problem of overfitting\n",
        "model2.add(Dense(1, activation='sigmoid')) # Dense output layer with a single neuron and a sigmoid activation function to make 0 or 1 predictions"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxUblbqymXw-"
      },
      "source": [
        "#Built 2 models\n",
        "#model is 2 layer bidirectional LSTM using Keras functional API\n",
        "#model2 is 2 layer bidirectional LSTM without using Keras functional API"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRvmZUmO-U5n"
      },
      "source": [
        "Train and evaluate the model. Use Accuracy to evalaute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTtKk_zL-Vg7"
      },
      "source": [
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r2cl9ni6A-7",
        "outputId": "f4193bf4-d2be-4413-efab-0e6d9302045c"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=32, epochs=3, validation_data=(X_val, y_val))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "782/782 [==============================] - 502s 633ms/step - loss: 0.4633 - accuracy: 0.7676 - val_loss: 0.4171 - val_accuracy: 0.8087\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 470s 602ms/step - loss: 0.2798 - accuracy: 0.8898 - val_loss: 0.3798 - val_accuracy: 0.8572\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 476s 609ms/step - loss: 0.1539 - accuracy: 0.9472 - val_loss: 0.3822 - val_accuracy: 0.8611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffa09ecc7d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNQOhROhYULt"
      },
      "source": [
        "model2.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHhnXzTNYUZo",
        "outputId": "7e66e759-c6f9-44ad-dd6b-ad65bbec9de1"
      },
      "source": [
        "model2.fit(X_train, y_train, batch_size=32, epochs=3, validation_data=(X_val, y_val))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "782/782 [==============================] - 508s 641ms/step - loss: 0.5240 - accuracy: 0.6988 - val_loss: 0.3673 - val_accuracy: 0.8361\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 496s 635ms/step - loss: 0.2267 - accuracy: 0.9142 - val_loss: 0.3310 - val_accuracy: 0.8589\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 501s 640ms/step - loss: 0.1380 - accuracy: 0.9498 - val_loss: 0.3554 - val_accuracy: 0.8634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffa055c7ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skffkIi3lIJq",
        "outputId": "c3f374ee-f072-4965-c92b-6a1c0a6434a5"
      },
      "source": [
        "model2.evaluate(X_val, y_val)\n",
        "#Accuracy of model2 is 86.34%"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 95s 121ms/step - loss: 0.3554 - accuracy: 0.8634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3553614318370819, 0.8634399771690369]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFq6HzdkmPSz",
        "outputId": "b5c83c7d-9586-436f-833e-9c3ec69dce95"
      },
      "source": [
        "model.evaluate(X_val, y_val)\n",
        "#Accuracy of model is 86.11%"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 90s 115ms/step - loss: 0.3822 - accuracy: 0.8611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38224631547927856, 0.8610799908638]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}