{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgdXDoxU8EQh"
   },
   "source": [
    "1. Submit the screenshot of the driverless AI demo - 1 point - Upload in Canvas along with this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0EebyfI8EQl"
   },
   "outputs": [],
   "source": [
    "Submitted PDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQrAkkqf8EQm"
   },
   "source": [
    "2. After the demo, find out the model given by driveless AI for the Titanic dataset  - Just the model name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMOvf0ee8EQm"
   },
   "source": [
    "LightGBM model(from gradient Boosting framework)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8mZsLtB8EQn"
   },
   "source": [
    "3. Use logistic regression on this problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "Ap13dMzd8EQo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Titanic dataset\n",
    "data = pd.read_csv('titanic.csv')\n",
    "data.head()\n",
    "data.shape\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre processing data\n",
    "data.isnull().sum() # Data has lot of missing values in Age & Cabin features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing values of age using median value\n",
    "data['Age'].median()\n",
    "data['Age'][data['Age'].isna()] = data['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    int64  \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(6), object(4)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical features\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(data['Sex'])\n",
    "data['Sex']=encoder.transform(data['Sex'])\n",
    "print(data.shape)\n",
    "data.info()\n",
    "data['Embarked'] = pd.get_dummies(data['Embarked'])\n",
    "data['Cabin'] = pd.get_dummies(data['Cabin']) # Missing values are filled using get dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc(axis=1)['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Cabin']\n",
    "Y = data.loc(axis=1)['Survived']\n",
    "Y.head()\n",
    "# Scaling input data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "# Splitting data in 75:25 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25,random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.82062780269058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       128\n",
      "           1       0.80      0.71      0.75        95\n",
      "\n",
      "    accuracy                           0.80       223\n",
      "   macro avg       0.80      0.79      0.79       223\n",
      "weighted avg       0.80      0.80      0.80       223\n",
      "\n",
      "6.969769196983381\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,np.ravel(y_train,order='C'))\n",
    "y_pred = model.predict(X_test)\n",
    "print(model.score(X_test,y_test) *100)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2NTpmVd8EQo"
   },
   "source": [
    "4. Compare the accuracy from the driverless AI and your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIK9MQRE8EQo"
   },
   "source": [
    "Accuracy of drverless AI is 84.5% \n",
    "For survived class \n",
    "Precision is 75%\n",
    "Recall is 75%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASCwgMCpOxr8"
   },
   "source": [
    "Acuuracy of model using logistuc regression is 80%.\n",
    "For survived class \n",
    "Precision is 80% \n",
    "recall is 80%\n",
    "f1 score is 75%.\n",
    "It can be observed that lightGBM is better model than logistic regression in terms of accuracy but logistic regression has relatively more precision"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
